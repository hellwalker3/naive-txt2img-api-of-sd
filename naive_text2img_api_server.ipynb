{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM1d+Au4tRaTBv99n8laPQE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellwalker3/naive-txt2img-api-of-sd/blob/main/naive_text2img_api_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS8p2nU_MXCh"
      },
      "outputs": [],
      "source": [
        "#@title Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install\n",
        "\n",
        "# webui\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "\n",
        "# models\n",
        "!wget https://huggingface.co/dreamlike-art/dreamlike-anime-1.0/resolve/main/dreamlike-anime-1.0.safetensors -O /content/stable-diffusion-webui/models/Stable-diffusion/dreamlike-anime-1.0.safetensors \n",
        "!wget https://huggingface.co/datasets/gsdf/EasyNegative/resolve/main/EasyNegative.safetensors -O /content/stable-diffusion-webui/models/embeddings/EasyNegative.safetensors\n",
        "\n",
        "# extensions\n",
        "!cd /content/stable-diffusion-webui/extensions && git clone ttps://github.com/yfszzx/stable-diffusion-webui-images-browser.git\n",
        "!cd /content/stable-diffusion-webui/extensions && git clone https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git\n",
        "!cd /content/stable-diffusion-webui/extensions && git clone https://github.com/Mikubill/sd-webui-controlnet.git\n",
        "!cd /content/stable-diffusion-webui/extensions && git clone https://github.com/kohya-ss/sd-webui-additional-networks.git\n",
        "#!cd /content/stable-diffusion-webui/extensions && git clone https://github.com/opparco/stable-diffusion-webui-two-shot.git\n",
        "\n",
        "# controlnet and T2I-Adapter\n",
        "!wget https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/t2iadapter_keypose_sd14v1.pth\n",
        "!wget https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/t2iadapter_color_sd14v1.pth\n",
        "#!wget https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_seg_fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/diff_control_sd15_seg_fp16.safetensors\n",
        "!wget https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_canny_fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/diff_control_sd15_canny_fp16.safetensors\n",
        "#!wget https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_normal_fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/diff_control_sd15_normal_fp16.safetensors\n",
        "#!wget https://huggingface.co/kohya-ss/ControlNet-diff-modules/resolve/main/diff_control_sd15_depth_fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/diff_control_sd15_depth_fp16.safetensors\n",
        "\n",
        "# modules\n",
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117"
      ],
      "metadata": {
        "id": "hx7qWY5cNJC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Using an older version of controlnet due to difficulty with the latest version and passing special instances as arguments to the txt2img function\n",
        "!cd /content/stable-diffusion-webui/extensions/sd-webui-controlnet && git checkout b6fc297"
      ],
      "metadata": {
        "id": "FVGHjC-DNU5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copy LoRA file (if you have)\n",
        "from glob import glob\n",
        "lora_folder_path = \"/content/drive/MyDrive/dreambooth_models\"\n",
        "for file in glob(f'{lora_folder_path}/*'):\n",
        "      !cp {file} /content/stable-diffusion-webui/extensions/sd-webui-additional-networks/models/lora"
      ],
      "metadata": {
        "id": "CUrV5NfYNU8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Add txt2img2 API (Modifications required for extensions needing non-controlnet images, as they're not supported)\n",
        "#I believe it's a bad practice, but I am overwriting the file\n",
        "\n",
        "base_path ='/content'\n",
        "\n",
        "add_api = \"\"\"\n",
        "import os\n",
        "from contextlib import redirect_stdout\n",
        "class Api(Api):\n",
        "    def __init__(self, app: FastAPI, queue_lock: Lock):\n",
        "        super().__init__(app, queue_lock)\n",
        "        self.add_api_route(\"/sdapi/v1/txt2img2\", self.text2imgapi2, methods=[\"POST\"], response_model=dict)\n",
        "\n",
        "    def text2imgapi2(self, txt2imgreq: dict):\n",
        "        with redirect_stdout(open(os.devnull, 'w')):\n",
        "            from modules.generation_parameters_copypaste import create_override_settings_dict\n",
        "            override_settings = create_override_settings_dict(txt2imgreq['override_settings_texts'])\n",
        "            p = StableDiffusionProcessingTxt2Img(\n",
        "                sd_model=shared.sd_model,\n",
        "                do_not_save_samples=True,\n",
        "                do_not_save_grid=True,\n",
        "                prompt=txt2imgreq['prompt'],\n",
        "                negative_prompt=txt2imgreq['negative_prompt'],\n",
        "                seed=txt2imgreq['seed'],\n",
        "                subseed=txt2imgreq['subseed'],\n",
        "                subseed_strength=txt2imgreq['subseed_strength'],\n",
        "                seed_resize_from_h=txt2imgreq['seed_resize_from_h'],\n",
        "                seed_resize_from_w=txt2imgreq['seed_resize_from_w'],\n",
        "                seed_enable_extras=txt2imgreq['seed_enable_extras'],\n",
        "                sampler_name=sd_samplers.samplers[txt2imgreq['sampler_index']].name,\n",
        "                batch_size=txt2imgreq['batch_size'],\n",
        "                n_iter=txt2imgreq['n_iter'],\n",
        "                steps=txt2imgreq['steps'],\n",
        "                cfg_scale=txt2imgreq['cfg_scale'],\n",
        "                width=txt2imgreq['width'],\n",
        "                height=txt2imgreq['height'],\n",
        "                restore_faces=txt2imgreq['restore_faces'],\n",
        "                tiling=txt2imgreq['tiling'],\n",
        "                enable_hr=txt2imgreq['enable_hr'],\n",
        "                denoising_strength=txt2imgreq['denoising_strength'] if txt2imgreq['enable_hr'] else None,\n",
        "                hr_scale=txt2imgreq['hr_scale'],\n",
        "                hr_upscaler=txt2imgreq['hr_upscaler'],\n",
        "                hr_second_pass_steps=txt2imgreq['hr_second_pass_steps'],\n",
        "                hr_resize_x=txt2imgreq['hr_resize_x'],\n",
        "                hr_resize_y=txt2imgreq['hr_resize_y'],\n",
        "                override_settings=override_settings,\n",
        "            )\n",
        "            p.scripts = scripts.scripts_txt2img\n",
        "            import numpy as np\n",
        "            def decode_dict(dct):\n",
        "                dct['image'] = np.array(decode_base64_to_image(dct['image']))\n",
        "                dct['mask'] = np.tile([0, 0, 0, 225], dct['image'].shape[:2]).reshape(*dct['image'].shape[:2], 4).astype(np.uint8)\n",
        "\n",
        "            def decode_tuple(tpl):\n",
        "                lst = list(tpl)\n",
        "                for i in range(len(lst)):\n",
        "                    if isinstance(lst[i], dict):\n",
        "                        decode_dict(lst[i])\n",
        "                return tuple(lst)\n",
        "\n",
        "            args = decode_tuple(txt2imgreq['args'])\n",
        "            p.script_args = args\n",
        "\n",
        "        \n",
        "            with self.queue_lock:\n",
        "                shared.state.begin()\n",
        "                processed = scripts.scripts_txt2img.run(p, *args)\n",
        "                if processed is None:\n",
        "                    processed = process_images(p)\n",
        "                p.close()\n",
        "                shared.total_tqdm.clear()\n",
        "                shared.state.end()\n",
        "\n",
        "        b64images = list(map(encode_pil_to_base64, processed.images))\n",
        "\n",
        "        return {'images':b64images}\n",
        "        #, 'info':processed.js()}\n",
        "\"\"\"\n",
        "\n",
        "file_path = f'{base_path}/stable-diffusion-webui/modules/api/api.py'\n",
        "program_to_append = add_api\n",
        "with open(file_path, 'a') as f:\n",
        "    f.write('\\n' + program_to_append)"
      ],
      "metadata": {
        "id": "r9eODZfHNU_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Add a process to display the arguments passed during txt2img execution in the web UI (for use when running the API).\n",
        "\n",
        "target_file = f'{base_path}/stable-diffusion-webui/modules/txt2img.py'\n",
        "\n",
        "with open(target_file, 'r') as f:\n",
        "    contents = f.read()\n",
        "\n",
        "\n",
        "old_str = \"\"\"\n",
        "def txt2img(id_task: str, prompt: str, negative_prompt: str, prompt_styles, steps: int, sampler_index: int, restore_faces: bool, tiling: bool, n_iter: int, batch_size: int, cfg_scale: float, seed: int, subseed: int, subseed_strength: float, seed_resize_from_h: int, seed_resize_from_w: int, seed_enable_extras: bool, height: int, width: int, enable_hr: bool, denoising_strength: float, hr_scale: float, hr_upscaler: str, hr_second_pass_steps: int, hr_resize_x: int, hr_resize_y: int, override_settings_texts, *args):\n",
        "\"\"\"\n",
        "new_str = \"\"\"\n",
        "def txt2img(id_task: str, prompt: str, negative_prompt: str, prompt_styles, steps: int, sampler_index: int, restore_faces: bool, tiling: bool, n_iter: int, batch_size: int, cfg_scale: float, seed: int, subseed: int, subseed_strength: float, seed_resize_from_h: int, seed_resize_from_w: int, seed_enable_extras: bool, height: int, width: int, enable_hr: bool, denoising_strength: float, hr_scale: float, hr_upscaler: str, hr_second_pass_steps: int, hr_resize_x: int, hr_resize_y: int, override_settings_texts, *args):\n",
        "    def print_as_dict(id_task, prompt, negative_prompt, prompt_styles, steps, sampler_index, restore_faces, tiling, n_iter, batch_size, cfg_scale, seed, subseed, subseed_strength, seed_resize_from_h, seed_resize_from_w, seed_enable_extras, height, width, enable_hr, denoising_strength, hr_scale, hr_upscaler, hr_second_pass_steps, hr_resize_x, hr_resize_y, override_settings_texts, *args):\n",
        "        variables = {\n",
        "            'id_task': id_task,\n",
        "            'prompt': prompt,\n",
        "            'negative_prompt': negative_prompt,\n",
        "            'prompt_styles': prompt_styles,\n",
        "            'steps': steps,\n",
        "            'sampler_index': sampler_index,\n",
        "            'restore_faces': restore_faces,\n",
        "            'tiling': tiling,\n",
        "            'n_iter': n_iter,\n",
        "            'batch_size': batch_size,\n",
        "            'cfg_scale': cfg_scale,\n",
        "            'seed': seed,\n",
        "            'subseed': subseed,\n",
        "            'subseed_strength': subseed_strength,\n",
        "            'seed_resize_from_h': seed_resize_from_h,\n",
        "            'seed_resize_from_w': seed_resize_from_w,\n",
        "            'seed_enable_extras': seed_enable_extras,\n",
        "            'height': height,\n",
        "            'width': width,\n",
        "            'enable_hr': enable_hr,\n",
        "            'denoising_strength': denoising_strength,\n",
        "            'hr_scale': hr_scale,\n",
        "            'hr_upscaler': hr_upscaler,\n",
        "            'hr_second_pass_steps': hr_second_pass_steps,\n",
        "            'hr_resize_x': hr_resize_x,\n",
        "            'hr_resize_y': hr_resize_y,\n",
        "            'override_settings_texts': override_settings_texts,\n",
        "            'args': args\n",
        "        }\n",
        "        print(variables)\n",
        "    \n",
        "    print_as_dict(id_task, prompt, negative_prompt, prompt_styles, steps, sampler_index, restore_faces, tiling, n_iter, batch_size, cfg_scale, seed, subseed, subseed_strength, seed_resize_from_h, seed_resize_from_w, seed_enable_extras, height, width, enable_hr, denoising_strength, hr_scale, hr_upscaler, hr_second_pass_steps, hr_resize_x, hr_resize_y, override_settings_texts, *args)\n",
        "\"\"\"\n",
        "contents = contents.replace(old_str, new_str)\n",
        "\n",
        "with open(target_file, 'w') as f:\n",
        "    f.write(contents)\n"
      ],
      "metadata": {
        "id": "j193r4FqNVBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Launching webui and API server (for example, when using multiple controlnet instances, update settings and restart)\n",
        "!COMMANDLINE_ARGS=\"--api --enable-insecure-extension-access --share --disable-safe-unpickle --xformers\" REQS_FILE=\"requirements.txt\" python launch.py"
      ],
      "metadata": {
        "id": "eO2FvqgdOk4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  First, perform a sample run in the webui to check the arguments passed to txt2img (arguments will be displayed in dictionary format starting with 'id_task'), then execute the API based on those arguments (naive_text2img_api_client.ipynb)"
      ],
      "metadata": {
        "id": "il2PCEUnOk7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}